{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Lab-06 ------------27/9/24"
      ],
      "metadata": {
        "id": "sc2mY0h_z5NV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Nikhil Kuchana*"
      ],
      "metadata": {
        "id": "HBlp7txTgMn1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2303A51LB0**"
      ],
      "metadata": {
        "id": "wHQEjIJb0H4z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.Load data fromkeras.datasets and perform following computational analysis:-\n",
        "(a) Preprocessing of the Data\n",
        "\n",
        "(b) Divide data into training and testing data set\n",
        "\n",
        "(c) Build the Gated Recurrent Units (GRU) Model\n",
        "\n",
        "(d) Training the GRU Model\n",
        "\n",
        "(e) Text Generation Using the Trained Model\n",
        "\n",
        " (f)  Evaluate Model’s accuracy"
      ],
      "metadata": {
        "id": "qP136WMO0PQk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Load data fromkeras.datasets and perform following computational analysis:-\n",
        "\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# (a) Preprocessing of the Data\n",
        "# Load the data from keras.datasets (e.g., IMDB dataset for sentiment analysis)\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.imdb.load_data(num_words=10000)\n",
        "\n",
        "# Pad sequences to a fixed length for consistent input to the model\n",
        "maxlen = 200\n",
        "x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = keras.preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "\n",
        "# (b) Divide data into training and testing data set\n",
        "# Already loaded and preprocessed above (x_train, y_train, x_test, y_test)\n",
        "\n",
        "\n",
        "# (c) Build the Gated Recurrent Units (GRU) Model\n",
        "model = keras.Sequential()\n",
        "model.add(layers.Embedding(10000, 128))\n",
        "model.add(layers.GRU(128))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "# (d) Training the GRU Model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, epochs=3, batch_size=64, validation_split=0.2)\n",
        "\n",
        "\n",
        "# (e) Text Generation Using the Trained Model\n",
        "# (This part depends on the specific task. For example, if it's language modeling,\n",
        "# you can use the model to generate text based on a seed input.)\n",
        "# You can use the model.predict() method with a given input sequence to\n",
        "# generate the next word or character probability distribution.\n",
        "\n",
        "# (f) Evaluate Model's accuracy\n",
        "loss, accuracy = model.evaluate(x_test, y_test)\n",
        "print('Test accuracy:', accuracy)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sl3LBVjqwJ1z",
        "outputId": "0ec1d876-a69b-4362-caee-8b810249d1f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 597ms/step - accuracy: 0.6554 - loss: 0.5981 - val_accuracy: 0.8412 - val_loss: 0.3889\n",
            "Epoch 2/3\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 560ms/step - accuracy: 0.8701 - loss: 0.3049 - val_accuracy: 0.8654 - val_loss: 0.3427\n",
            "Epoch 3/3\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 557ms/step - accuracy: 0.9205 - loss: 0.2044 - val_accuracy: 0.8704 - val_loss: 0.3290\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 64ms/step - accuracy: 0.8585 - loss: 0.3527\n",
            "Test accuracy: 0.8621199727058411\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Compare accuracy of Long sort term memory and Gated recurrent Unit models for text generation using data from tensorflow.keras.datasets."
      ],
      "metadata": {
        "id": "Ns_NCO1_wI6p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bhy0caqIn4XS",
        "outputId": "238e7d1b-a82e-47c6-adf4-8fa11a95b927"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/3\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 339ms/step - accuracy: 0.7369 - loss: 0.5069 - val_accuracy: 0.8610 - val_loss: 0.3242\n",
            "Epoch 2/3\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 374ms/step - accuracy: 0.9044 - loss: 0.2442 - val_accuracy: 0.8722 - val_loss: 0.3258\n",
            "Epoch 3/3\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 371ms/step - accuracy: 0.9318 - loss: 0.1824 - val_accuracy: 0.8695 - val_loss: 0.3411\n",
            "Epoch 1/3\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 357ms/step - accuracy: 0.6867 - loss: 0.5580 - val_accuracy: 0.8544 - val_loss: 0.3393\n",
            "Epoch 2/3\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 391ms/step - accuracy: 0.8993 - loss: 0.2533 - val_accuracy: 0.8592 - val_loss: 0.3458\n",
            "Epoch 3/3\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 360ms/step - accuracy: 0.9374 - loss: 0.1673 - val_accuracy: 0.8700 - val_loss: 0.3258\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 37ms/step - accuracy: 0.8692 - loss: 0.3420\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 35ms/step - accuracy: 0.8689 - loss: 0.3283\n",
            "LSTM Accuracy: 0.8694800138473511\n",
            "GRU Accuracy: 0.8700399994850159\n",
            "GRU model has higher accuracy.\n"
          ]
        }
      ],
      "source": [
        "# prompt: 2.Compare accuracy of Long sort term memory and Gated recurrent Unit models for text generation using data from tensorflow.keras.datasets\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, GRU, Dense\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the IMDB dataset\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
        "\n",
        "# Pad sequences to a fixed length\n",
        "max_length = 200\n",
        "x_train = pad_sequences(x_train, maxlen=max_length)\n",
        "x_test = pad_sequences(x_test, maxlen=max_length)\n",
        "\n",
        "# Define LSTM model\n",
        "lstm_model = Sequential()\n",
        "lstm_model.add(Embedding(10000, 128))\n",
        "lstm_model.add(LSTM(64))\n",
        "lstm_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile LSTM model\n",
        "lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define GRU model\n",
        "gru_model = Sequential()\n",
        "gru_model.add(Embedding(10000, 128))\n",
        "gru_model.add(GRU(64))\n",
        "gru_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile GRU model\n",
        "gru_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train LSTM model\n",
        "lstm_model.fit(x_train, y_train, epochs=3, batch_size=64, validation_data=(x_test, y_test))\n",
        "\n",
        "# Train GRU model\n",
        "gru_model.fit(x_train, y_train, epochs=3, batch_size=64, validation_data=(x_test, y_test))\n",
        "\n",
        "# Evaluate models\n",
        "lstm_loss, lstm_accuracy = lstm_model.evaluate(x_test, y_test)\n",
        "gru_loss, gru_accuracy = gru_model.evaluate(x_test, y_test)\n",
        "\n",
        "# Compare accuracy\n",
        "print(\"LSTM Accuracy:\", lstm_accuracy)\n",
        "print(\"GRU Accuracy:\", gru_accuracy)\n",
        "\n",
        "if lstm_accuracy > gru_accuracy:\n",
        "    print(\"LSTM model has higher accuracy.\")\n",
        "elif gru_accuracy > lstm_accuracy:\n",
        "    print(\"GRU model has higher accuracy.\")\n",
        "else:\n",
        "    print(\"Both models have the same accuracy.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k5Ye9aEY0S3n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}